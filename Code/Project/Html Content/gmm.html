<!DOCTYPE html>
<html>

<head>
    <title>GMM</title>
    <link rel="stylesheet" href="style.css">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.13.1/css/all.css" integrity="sha384-xxzQGERXS00kBmZW/6qxqJPyxW3UR0BPsL4c8ILaIWXva5kFi7TxkIIaMiKtqV1Q" crossorigin="anonymous">
</head>

<body>
    <main>
        <main>
            <nav role="navigation">
                <div id="menuToggle">
                    <!--
                                            A fake / hidden checkbox is used as click reciever,
                                            so you can use the :checked selector on it.
                                            -->
                    <input type="checkbox" />

                    <!--
                                            Some spans to act as a hamburger.
                                            
                                            They are acting like a real hamburger,
                                            not that McDonalds stuff.
                                            -->
                    <span></span>
                    <span></span>
                    <span></span>

                    <!--
                                            Too bad the menu has to be inside of the button
                                            but hey, it's pure CSS magic.
                                            -->
                    <ul id="menu">
                        <a href="welcome.html">
                            <li>Welcome</li>
                        </a>
                        <a href="whatismachinelearning.html">
                            <li>What is Machine Learning?</li>
                        </a>
                        <a href="taskdrivenvsdatadriven.html">
                            <li>Task Driven vs Data Driven</li>
                        </a>
                        <a href="supervisedvsunsupervised.html">
                            <li>Supervised and Unsupervised Learning</li>
                        </a>
                        <a href="classification.html">
                            <li>Classification</li>
                        </a>
                        <ul>
                            <a href="svm.html">
                                <li>Support Vector Machines (SVM)</li>
                            </a>
                            <a href="knearestneighbour.html">
                                <li>Nearest Neighbour</li>
                            </a>
                            <a href="neuralnetworks.html">
                                <li>Neural Networks</li>
                            </a>
                        </ul>
                        <a href="regression.html">
                            <li>Regression</li>
                        </a>
                        <ul>
                            <a href="linearregression.html">
                                <li>Linear Regression</li>
                            </a>
                            <a href="logisticregression.html">
                                <li>Logistic Regression</li>
                            </a>
                        </ul>


                        <a href="clustering.html">
                            <li>Clustering</li>
                        </a>
                        <ul>
                            <a href="kmeans.html">
                                <li>K-Means</li>
                            </a>
                            <a href="gmm.html">
                                <li>Gaussian Mixture Model (GMM)</li>
                            </a>
                        </ul>
                        <a href="dr.html">
                            <li>Dimensionality Reduction</li>
                        </a>
                        <ul>
                            <a href="pca.html">
                                <li>PCA</li>
                            </a>
                            <a href="lda.html">
                                <li>LDA</li>
                            </a>
                        </ul>
                        <a href="associationrule.html">
                            <li>Association Rule</li>
                        </a>
                    </ul>
                </div>
            </nav>

            <div class="container">

                <div class="textBackground">
                    <img class="titlePageImg" src="./Images/gmm.png" alt="Neural Network Title Image" />
                </div>

                <div class="textBackgroundLight">
                    <p>
                        Gaussian mixture models (GMM) are a probabilistic model for representing normally distributed subpopulations within an overall population. Mixture models in general don't require knowing which subpopulation a data point belongs to, allowing the model
                        to learn the subpopulations automatically. Since subpopulation assignment is not known, this constitutes a form of unsupervised learning.
                    </p>
                </div>

                <div class="textBackground">
                    <h2>What is a GMM?</h2>
                </div>
                <div class="textBackgroundLight">
                    <p>
                        GMM is a <b>unsupervised</b> learning model. Unlike K-Means which aims to minimise the <b>Sum of Squared Error</b>, GMM is a model based approach to data clustering. The model is described by a set of parameters, which are several.
                        However, as a GMM is not a single Gaussian function, it is not considered a parametric model.
                    </p>
                    <p>
                        GMM use a Gaussian distribution, which is also known as a normal distribution (shown below).
                        <img src="https://latex.codecogs.com/gif.latex?\mu" title="\mu" /> (Mu) is the mean and <img src="https://latex.codecogs.com/gif.latex?\sigma" title="\sigma" /> (Sigma) is the standard deviation.

                    </p>

                    <p>
                        <img src="./Images/normal dist.png" class="ImgCentreShortMedium" alt="">
                    </p>
                    <p>
                        We can use a mixture of Gaussian functions to learn the distribution of the data. The distribution of the data is modelled by a set of parameters:
                        <ul>
                            <li><img src="https://latex.codecogs.com/gif.latex?k" title="k" />, the number of Gaussian functions - like K-Means and the number of <img src="https://latex.codecogs.com/gif.latex?k" title="k" /> clusters.</li>
                            <li><img src="https://latex.codecogs.com/gif.latex?\mu" title="\mu" />, the mean of the Gaussian function.</li>
                            <li><img src="https://latex.codecogs.com/gif.latex?\sigma" title="\sigma" />, the standard deviation for each gaussian function. It can also be seen as the covarience matrix <img src="https://latex.codecogs.com/gif.latex?\sum"
                                    title="\sum" /> for each Gaussian.</li>
                            <li><img src="https://latex.codecogs.com/gif.latex?P" title="P" />, the mixing coefficient. This is the weights for each Guassian function.</li>
                        </ul>
                        GMM are good at modelling multimodal distributions (see image below). Red curve is the R channel histogram and the blue curves are the two Gaussian functions.
                    </p>
                    <p>
                        <img src="./Images/gmm example.png" class="ImgCentreShortSmall" alt="">
                    </p>
                    <p>
                        GMM is described as a weighted sum of single Gaussian functions (shown below). <img src="https://latex.codecogs.com/gif.latex?P_j" title="P_j" /> are the mixing coefficient. This is also known as the prior probability. j indicatates
                        the jth Gaussian function within the GMM.
                    </p>
                    <p>
                        <img src="./Images/gmm weighted sum.png" class="ImgCentreShortSmall" alt="">
                    </p>
                </div>

                <div class="textBackground">
                    <h2>The Stages of GMM</h2>
                </div>

                <div class="textBackgroundLight">
                    <p>
                        <ol>
                            <li>
                                Initialisation of te learning GMM parameters.
                            </li>
                            <li>
                                Set the posterior probability of the learning GMM parameters.
                            </li>
                            <li>
                                Updating the learning parameters.
                            </li>
                            <li>
                                Repest stages 2 and 3 until the model stabalises and converges.
                            </li>
                        </ol>
                    </p>
                </div>


                <!-- Footer -->
                <footer>

                    <!-- Copyright -->
                    <div>
                        <a href="kmeans.html"><i class="far fa-arrow-alt-circle-left"
                                style="padding-left: 38%;"></i>
                            Previous</a> <a href="dd.html"><span style="padding-left: 20px;">Next</span> <i
                                class="fas fa-arrow-circle-right"></i></a>
                    </div>
                    <!-- Copyright -->

                </footer>
                <!-- Footer -->

            </div>
        </main>
</body>

</html>