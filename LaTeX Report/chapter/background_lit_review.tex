\chapter{Background \& Literature Review}
	\label{chap:background_lit_review}
	
	
	\section{Introduction to Edu-Games}
	
	
	
	\subsection{Gamification}
	%%% From HCI Report
	We wanted to find out what the context of gamification is, and how it can be used within education, to take aspects of teaching and learning that can get brought into the 21st Century. To make aspects of education more accessible to students in a manner that they are more accustomed to in their everyday lives. 
	
	Gamification, a term first coined in 2002, is an HCI technique used to add a game layer to traditional non-game like situations. The gamification aims to create extrinsic motivators for a person to be encouraged to do particular actions. Each action, upon completion, will have a little reward which, upon doing so, will release dopamine into the brain. The release of dopamine creates a good feeling within the participant's mind, which in turn is encouraging them to do it again. These rewards can be in the form of badges, achievements or progress bars, to name a few.
	
	The term gamification first appeared in the context of software design in 2008 \cite{4}, but the term only started to get more widespread recognition within 2010. However, the term "gamification" was first coined by Nick Pelling in 2002 \cite{3e}. Its initial aim was to incorporate the social and reward features of games into the software. Gamification started to gain much attention, so much so that it got described by a venture capitalist as one of the most promising areas of gaming \cite{5}. Gamification is now known as a powerful tool for engagement, which has, since its initial conception, now become a standard feature within software development \cite{3e}. Researchers consider gamification to be the progression of earlier work that focuses on adopting game-design elements to non-game situations and contexts. Research in the HCI field, in regards to apps that use game-driven features for motivation and also in interface design, suggest that there is a connection between Soviet concepts of socialist competition and the American management trend of "fun at work" \cite{5}. 
	
	Jane McGonigal, in 2010, delivered a groundbreaking TED Talk titled, "Gaming Can Make a Better World' \cite{6}. This talk gets reflected as the defining moment in the history of gamification. Within the talk, she foretells a game based utopia. Where she states that "When I look forward to the next decade, I know two things for sure: that we can make any future we can imagine, and we can play any games we want, so I say: Let the world-changing games begin \cite{6}." Hindsight tells she was correct, as, from 2011, gamification starts to pick up steam.  At a Computer-Human Interaction (CHI) conference, a workshop titled "Gamification: Using Game Design Elements in Non-Gaming Contexts \cite{7}", which generated the Gamification Research Network (GRN) \cite{11}, in the year 2011. Through the years 2012 to 2016, gamification continues to grow. Even so, that gamification goes viral without people knowing through a game called Pokémon Go. Pokémon Go is one of the most successful applications of gamification with over 800 million downloads. People who would usually turn their nose up at badge collecting were out patrolling the streets searching for rare Pokémon. Pokémon Go is one of the most successful apps of all time. It even broke records \cite{3e,8}. It could be said thanks to Pokémon Go, that gamification is now everywhere. Many established technology and other companies, including SAP AG, Microsoft, IBM, SAP, LiveOps, Deloitte, and other companies have started using gamification in various applications and processes \cite{9}. 
	
	The increased popularity in gamification, within some contexts, has had led to many legal restrictions be placed upon it, especially when linked to the Internet of Things (IoT) features. However, this mainly refers to the use of virtual currencies and assets, as well as data privacy, data protection and labour laws. These laws are due to its nature of being a data mining systems that spread information online, known as data aggregator \cite{10, 11}. 
	%%%%%%%
	
	
	\subsection{Gamification in Education}
	%%% Taken from HCI report
	The gamification within a learning setting is a pedagogical approach to motivate students. This approach tried to help students learn by using gaming elements within a learning environment \cite{22}. Gamification within education is very much the same thing, in general, as gamification. However, within education, it has a focus on aiding learning instead. Gamification in learning has two main views. One of the views categories gamification of learning as learning which has game-like characteristics. However, this view believes it is only the case when only when the learning is happening in a non-game setting, like a classroom. This view would involve a range of elements that get presented in a  game layer which attempts to happen alongside the learning in a traditional classroom. The other view has the same views as the view just mentioned, but the other half also include games that get designed to provoke learning within them \cite{22}. 
	
	Gamification, within an educational or a learning situation, has many benefits. While traditionally gamification has been used to improve attendance with incentives by reaching a set score or receiving extra prizes for completing designated tasks within a lesson. It can also aid in cognitive development within youngsters, which can boost levels of engagement and can assist with accessibility within the classroom \cite{24}. Games that get created for improving cognitive development are known as "brain games" \cite{24}. These popular games typically are focused around a series of questions and problems to solve or answer. These games develop the rate the player can sustain information and increase the brain's ability to process knowledge. The levels of the engagement increases when gamification has gets used within a classroom \cite{25}. A study performed by scientists aimed to measure the students' levels of engagement in a classroom where gamification elements are applied \cite{25}. They assigned a point system to multiple daily activities, and every student had a measurement of their observed level of engagement. The finding showed that the game like setting was supporting the learning within the classroom and increased productivity. Therefore, by increasing engagement levels, it also means it helps students be able to access the content of the lesson better. 
	
	Gamification of learning has excellent potential benefits. The gains allow students to have ownership of their education, as well as giving opportunities for the learner to gain a sense of their "own identity" through alternative role-playing selves. The freedom that gets bundled without any negative repercussions allows the students to fail and keep on trying again. The ability to increase fun and joy while learning. The opportunity for tasks to be differentiated. Making the learning visible and providing opportunities to inspire intrinsic motivators for learning. Also, the ability to aiding in motivating students with low levels of motivation \cite{22}. 
	
	Even though gamification can aid teaching students of all needs, a study conducted on students who had autism using video games showed that this training method was powerful in teaching the content that was age-appropriate \cite{26}. However, gamification of learning is not something just for the classroom. It is an excellent tool for learning outside the classroom and allowing education to get conducted without an educational facilitator like a teacher. 
	
	%%% Taken from CSCM10 Report
	\subsection{Gamification in Science}
	\label{sec:game_in_science}
	
	Although science concepts still use more conventional styles of gamification. Science concepts will often use a type of gamification game that has a primary purpose, which is other than just for pure fun, called a 'serious' or 'applied' game. These types of games get utilised by industries like scientific exploration, education, health care, defence, emergency management, city planning, engineering and politics \cite{wikiserious}. Although not all do, serious games tend to share aspects closely tied with simulational games. However, all serious games still have other gamification features included (see fig: \ref{fig:seriousg}).
	
	Nonetheless, in regards to the field of science, serious games' role is to include crucial activities for scientists. These include outreach, teaching and research. With serious games on the increase, an emerging sub-genre is called citizen science games (CSGs) \cite{10seriousrules}. CSGs enables the user to produce as well as, or instead, analyse data for scientific use. Some examples of CSGs are GalaxyZoo, Foldit and HiRE-RNA \cite{follett2015analysis,mazzanti2017can}
	
	Studies suggest that there are ten main rules for serious games to follow. These are \cite{10seriousrules}:
	
	\begin{enumerate}		
		\item Define a serious goal - we must first define the purpose of the game at the beginning of its development. Is its purpose for science, outreach, teaching or a combination of all three? 
		
		\item Get the balance between entertainment and serious tasks - the game design should be implemented as a function of the objectives of the game. Therefore equilibrium and compromise need to be found between scientific accuracy and player accessibility.
		
		\item Allow the player to interact with the scientific data - players interest increases if they can interact with the science data, enriching the learning experience. The ability for players to generate data also creates another perspective for the player, increasing interaction.
		
		\item Promote onboarding and engagement - Expectations of players are varied. Therefore the reward system needs to be versatile. Ideally, the entry-level should be low and the difficulty altered to each player.
		
		\item Manage Information Flow - How the information to the play gets received will impact their behaviour, either positively or negatively. So if the focusing is on the outcome, this could influence the results.
		
		\item Provide an appropriate narrative - This is important for all games, but also crucial for serious games. The narrative should give the player context to the game, allowing them to know what to do.
		
		\item Adapt the level design - Depending on the objective, variation on level designs needs implementing. These can include duration, tasks and difficulty. 
		
		\item Develop good graphics that are not just pleasing on the eye - High-quality graphics increase the player's immersion into the game.
		
		\item Use all modalities, especially sound - Using just a visual channel can overload the player. Therefore it is vital to take the load of the player's vision and use several different channels — for example, sound.
		
		\item Iteratively assess what works and what does not - However, it is vital to take into account three different perspectives for serious games. The developer, the player and the scientist as they all have different views on what they believe the game needs adapting based on their desires.
	\end{enumerate} %%%
	
	
	\subsection{Example Applications}
	

	\section{Machine Learning}
	
	\subsection{Machine Learning Fundamentals}
	
	
	\subsection{Supervised vs Unsupervised Learning}
	%%% Spec
	Within machine learning, there are multiple different learning styles. These styles are known as supervised, unsupervised, semi-supervised and reinforcement learning. However, we will only be focusing on the main two types of techniques, supervised and unsupervised learning. 
	
	Supervised learning trains a model on known input and output data so that it can predict future outputs, and unsupervised learning, which finds hidden patterns or intrinsic structures in input data \cite{geron2019hands}. Supervised machine learning aims to build a model that makes predictions based on evidence in the presence of uncertainty. The algorithms for supervised learning takes the knowledge it has gained from a known set of input data and known responses to the data (output). These known responses are also known as labels. The combination of the labels and the data helps train the model to generate reasonable predictions for the answer to new data getting presented to the model \cite{matlanintrotoml, geron2019hands}. 
	
	Supervised learning uses classification, like neural networks, k-Nearest Neighbours, Support Vector Machines, and regression techniques, like logistic and linear regression, to develop predictive models.  Classification is a technique that predicts discrete responses by aiming to classify the inputted data into different classes \cite{matlanintrotoml}. Some examples of this type of these methods are deciding if an email is spam or not, or deciding if a patient has a benign or cancerous tumour. These types of applications also included credit scoring, medical imaging and speech recognition. While supervised learnings other method, regression techniques, aims to predict continuous responses \cite{geron2019hands}. An excellent example of this is checking for changes in the temperature or for checking the power demands fluctuations and forecasting electricity load. These kinds of applications can also get used for trading  \cite{matlanintrotoml}.
	
	The other primary method learning, unsupervised learning, aims to find hidden patterns or intrinsic structures in the data \cite{geron2019hands}. In the same regard as supervised learning, unsupervised learning seeks to obtain insights from the data. However, where supervised learning has the output labels for the provided dataset, unsupervised does not. So unsupervised learning aims to explore the data to find patterns or groupings in the data \cite{matlanintrotoml}. Unsupervised learning can take the form of clustering, like k-means, GMM, or through a technique called association rule. Examples of clustering applications include gene sequence analysis, market research, and object recognition and examples of the association rule are services providing a recommendation, like Netflix's "watch next" or Amazon's "you might also like" \cite{matlanintrotoml}.
	
	
	\subsection{Methods}
	
	\subsubsection{K-Means}
	The KMeans algorithm aims to clusters the data by trying to separate samples into $n$ groups of equal variance. While also seeking to minimise a criterion known as the inertia or even referenced as a within-cluster sum-of-squares \cite{geron2019hands, sklearn_km}. The formula for the sum-of-squares is \cite{sklearn_km}: $\sum_{i=0}^{n}\min_{\mu_j \in C}(||x_i - \mu_j||^2)$. 
	
	This algorithm requires the number of clusters to get specified before initialising the model. The K-means algorithm strives to choose centroids that minimise the inertia, or within-cluster sum-of-squares criterion. The k-means algorithm divides a set of $N$ samples $X$ into $K$ disjoint clusters $C$, each described by the mean $\mu_j$ of the samples in the cluster. The means get commonly called the cluster's "centroids". However, these are not usually points from $X$, although they live in the same space. K-means gets associated with Lloyd's algorithm \cite{geron2019hands, sklearn_km}. 
	
	The algorithm has three steps. The first step chooses the initial centroids, with the most basic method being to choose k samples from the dataset $X$. After initialisation, K-means consists of looping between the two other steps. The first step assigns each sample to its nearest centroid. The second step creates new centroids by taking the mean value of all of the samples assigned to each previous centroid. The difference between the old and the new centroids get computed, and the algorithm iterates these last two steps until this value is less than a threshold. It is, in essence, repeating until the centroids do not move significantly \cite{geron2019hands, sklearn_km}.
	
	K-means scales well to a large number of samples and gets used across a broad range of application areas in many varied fields. K-means is equivalent to the expectation-maximisation algorithm with a small, all-equal, diagonal covariance matrix. When given enough time, K-means will always converge. However, this may be to a local minimum. Converging to a local minimum is highly dependent on the initialisation of the centroids. Therefore, as a result, the computation is often done several times, with different initialisations of the centroids \cite{sklearn_km}.
	
	\subsubsection{Gaussian Mixture Model}
	A Gaussian mixture model is a probabilistic model that assumes all the data points get generated from a mixture of a finite number of Gaussian distributions with unknown parameters \cite{geron2019hands, sklearn_gmm}. It can get thought of that Gaussian mixture models are a generalised form of k-means clustering to incorporate information about the covariance structure of the data as well as the centres of the underlying Gaussians \cite{sklearn_gmm}. 
	
	There are multiple GMM variants, but in its simplest form for the model to get implemented it requires to know in advance the number of $k$ Gaussian distributions. At the same time, an assumption on the dataset that it gets generated through a probabilistic process (displayed in fig:\ref{representation_of_gauss}) \cite{geron2019hands}. 
	
	GMM 's do have many advantages from its speed, and its agnostics, which is due to the algorithm only maximising the likelihood. However, GMM's do have some disadvantages. These are it suffering from singularities. This disadvantage causes the algorithm to diverge and find solutions with infinite likelihoods unless one regularises, which is due to handling of the estimates of the covariance matrices. These become difficult when the algorithm is dealing with insufficiently many points per mixture \cite{sklearn_gmm}. Another disadvantage is the algorithm dealing with several components. This disadvantage is due to the algorithm using all the features it has available. Forcing the need for held-out data to help decide on the number of components required in the absence of external cues \cite{sklearn_gmm}.
	
	\subsubsection{Neural Network}
	%%% Spec
	Linear regression is a model that aims to fit a line of best fit to the data provided \cite{geron2019hands, sklearn_lr}.  A requirement for linear regression is for a set of methods intended for regression in which the target value expects to be a linear combination of the features. In mathematical notation, if $\hat{y}$ is the predicted value. $\hat{y}(w,x)=w_0+w_1x_1+...+w_px_p$
	Across the module, we designate the vector $w=(w_1,...,w_p)$ as the coefficient and w0 as the intercept \cite{sklearn_lr}
	
	LinearRegression fits a linear model with coefficients $w=(w_1,...,w_p)$ to minimise the residual sum of squares between the observed targets in the dataset, and the targets predicted by the linear approximation \cite{sklearn_lr}. To achieve the best fit to the dataset the algorithm chooses the best overall score from the 'Root Mean Square Error' (RMSE). Therefore, to train a linear regression model, we need to find the value of $0$ that minimises the RMSE \cite{geron2019hands}.
	%%%
	Mathematically it solves a problem of the form \cite{sklearn_lr}:
	$\min\limits_{w} = ||Xw-y||^2_2$
	
	The coefficient estimates for linear regression rely on the independence of the features. When features are correlated, and the columns of the design matrix $X$ have an approximate linear dependence, the design matrix becomes close to the singular, which causes the least-squares estimate to become highly sensitive to random errors in the observed target, which in turn produces a large variance. This situation of multicollinearity can arise, for example, when data get collected without an experimental design \cite{sklearn_lr, geron2019hands}.
	
	\subsubsection{Logistic Regression}
	%%% Spec
	Logistic regression is an algorithm that gets used for classification and, despite its name, is a linear model rather than a regression one. Logistic regression gets also known in the literature as logit regression, maximum-entropy classification (MaxEnt) or the log-linear classifier. In this model, the probabilities describing the possible outcomes of a single trial getting modelled using a logistic function \cite{sklearn_lr, handson_book}. Logistic regression's model estimated probability in its vectorised form: $\hat{p}=h_\theta(x) = \sigma(x^T\theta)$ \cite{geron2019hands}.
	
	Logistic regression gets used to estimate the probability that an instance belongs to a particular class. If the estimated probability is greater than 50\%, the model predicts that the instance belongs to that class. If the model has predicted that the instance belongs to that class, also known as the positive class, it gets a '1' label  (see fig \ref{log regression}) \cite{handson_book, geron2019hands}. Logistic regression can fit binary, One-vs-Rest, or multinomial logistic regression. That also has an optional $\ell1, \ell2$ or Elastic-Net regularisation \cite{sklearn_lr}.
	
	\subsubsection{SVM}
	%%% Spec
	Support Vector Machine (SVM) is a powerful and versatile ML model. The model is capable of performing linear or nonlinear classification, regression and even outlier detection \cite{geron2019hands, sklearn_svm}. This model is one of the most popular ML models and is best suited for small to medium-sized datasets. The model aims to separate the data categories by using a decision boundary, with the largest margin between them. Due to the model using a large margin to separate the data, the algorithm gets known as the 'large margin classification' \cite{geron2019hands}.
	%%%
	
	SVMs are a set of supervised learning methods and have many advantages, especially when working in high dimensional spaces. SVMs are also useful in situations where the number of dimensions is greater than the number of samples. Due to the model using subsets of the training points in the decision function, the model is memory efficient, and it is very versatile. The model is very versatile due to the different kernel functions are can be used \cite{sklearn_svm}. Although the model does have many strengths, it does also have a few disadvantages. A disadvantage is if the number of features is considerably greater than the number of data samples, then overfitting can happen. A way to overcome this is to choose different kernel functions, and regularisation of the term is crucial. Another disadvantage is that SVMs do not provide probability estimates. These estimates get calculated by using an expensive five-fold cross-validation \cite{sklearn_svm}.
	
	\subsubsection{Linear Discriminant Analysis}
	
	\subsubsection{PCA}
	
	\subsubsection{kNN}
	
	
	\subsection{Machine Learning in Education}
		\label{seb_sec:ml_in_learning}
	
	We will look at the styles and way machine learning gets currently taught to help people learn the different aspects of machine learning and in most cases, the overall characteristics of data science. we will be looking at classical approaches as well at any modern-day style teaching or machine learning educational games available. 
	
	\subsubsection{Classical Approaches}
		\label{sub_sec:classical_teach_learn}
	
	
	\subsubsection{Machine Learning Edu-Games}
		\label{sub_sec:ml_edu_games}
	
	\section{Proposed Solution}
	% Taken from spec
	The overall aim of the proposed solution is to create a fun, educating game about ML. The players will be, at the core of the solution, playing a game that interacts with different ML models. The player(s) will be manipulating the game board and data points to affect the decision boundary, or to figure out where the decision boundary or centre of the cluster is. The solution will get created by using  Pygame and will have many different algorithms in the background, doing the main game mechanics, through using libraries like SKLearn \cite{sklearn_api} and Tensorflow \cite{tensorflow2015-whitepaper}.
	
	\section{Summary and Overview of Proposed Solution}
	